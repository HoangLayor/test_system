{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./dataset/test_data/OPUS-Tatoeba\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "ru_vi_url = \"https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/moses/ru-vi.txt.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MyTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Translators import OpusTranslator, NLLB200Translator, MBART50Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"Helsinki-NLP/opus-mt-ru-vi\"\n",
    "# model_name = \"Helsinki-NLP/opus-mt-vi-ru\"\n",
    "# model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "\n",
    "# direction = \"ru2vi\"\n",
    "direction = \"vi2ru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name.startswith(\"Helsinki-NLP/opus-mt\"):\n",
    "    # OpusTranslator\n",
    "    translator = OpusTranslator(model_name)\n",
    "elif model_name.startswith(\"facebook/nllb\"):\n",
    "    # NLLB200Translator\n",
    "    translator = NLLB200Translator(model_name, direction=direction)\n",
    "elif model_name.startswith(\"facebook/mbart\"):\n",
    "    # MBART50Translator\n",
    "    translator = MBART50Translator(model_name, direction=direction)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model name: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyDataset import TransDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_path = f\"{data_dir}/Tatoeba.ru-vi.ru\"\n",
    "vi_path = f\"{data_dir}/Tatoeba.ru-vi.vi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = translator.tokenizer\n",
    "myDataset = TransDataset(ru_path, vi_path, tokenizer, direction=direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tôi phải đi ngủ.', 'Мне пора идти спать.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources = myDataset.sources\n",
    "targets = myDataset.targets\n",
    "sources[0], targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 313/313 [00:45<00:00,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 45.95970892906189 seconds\n",
      "Average time per sentence: 0.146836130763776 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "start_time = time.time()\n",
    "# ----\n",
    "for sentence in tqdm(sources, desc=\"Translating\"):\n",
    "  predictions.append(translator.translate(sentence))\n",
    "# ----\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "average_time = (end_time - start_time) / len(sources)\n",
    "print(f\"Inference time: {total_time} seconds\")\n",
    "print(f\"Average time per sentence: {average_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Я должен спать.', 'Что вы делаете?', 'Что это?'],\n",
       " ['Мне пора идти спать.', 'Что ты делаешь?', 'Что это?'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:3], targets[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()\n",
    "eval_results = evaluator.compute(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 6.76488028685308\n"
     ]
    }
   ],
   "source": [
    "score = eval_results[\"score\"]\n",
    "print(f\"BLEU score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = model_name.split(\"/\")[-1]\n",
    "log_dir = f\"./logs/{model_log}_{direction}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_file_path = os.path.join(log_dir, f\"log_{model_log}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./logs/mbart-large-50-many-to-many-mmt_vi2ru/log_mbart-large-50-many-to-many-mmt.txt\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "results[\"model_name\"] = model_name\n",
    "results[\"average_time\"] = average_time\n",
    "results[\"total_time\"] = total_time\n",
    "results[\"num_sentences\"] = len(myDataset)\n",
    "results[\"BLEU_score\"] = score\n",
    "\n",
    "with open(log_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "  json.dump(results, f, indent=4, ensure_ascii=False)``\n",
    "print(f\"Results saved to {log_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./logs/mbart-large-50-many-to-many-mmt_vi2ru/predictions_mbart-large-50-many-to-many-mmt.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the dict {predictions, target} to a file\n",
    "predictions_file_path = os.path.join(log_dir, f\"predictions_{model_log}.txt\")\n",
    "with open(predictions_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "  for pred, target in zip(predictions, targets):\n",
    "    pair = {\"pred\": pred, \"target\": target}\n",
    "    f.write(json.dumps(pair, indent=4, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"Predictions saved to {predictions_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
